\begin{abstract}
Advances in convolutional neural networks have  made possible significant  improvements in the state-of-the-art in image classification. However, their success on a particular field rests on the possibility of obtaining labeled data to train networks.  Handshape recognition from images,  an important subtask  of both gesture and sign language recognition,  suffers from such a lack of data.  Furthermore,  hands are highly deformable objects and therefore handshape classification  models require larger datasets.

We analyze both state-of-the-art models for image classification, as well as data augmentation schemes and specific models to tackle  problems with small datasets.  In particular,  we perform experiments with Wide-DenseNet, a state-of-the-art convolutional architecture and Prototypical Networks, a state-of-the-art few-shot learning meta model. In both cases, we also quantify the impact of data augmentation on accuracy. 

Our results show that on small and simple data sets such as CIARP,  all models and variations of achieve perfect accuracy,  and therefore the utility of the data is highly doubtful, despite its having 6000  samples. On the other hand, in small but complex datasets such as LSA16 (800 samples),  specialized methods such as Prototypical Networks do have an advantage over other methods.  On RWTH, another complex and small dataset with close to 4000 samples,  a  traditional and state-of-the-art method such as Wide-DenseNet surpasses  all other models.  Also, data augmentation consistently increases accuracy for Wide-DenseNet,  but not full  Prototypical Networks.

\keywords{ sign language, hand shape recognition,convolutional neural networks,densenet,  prototypical networks, small datasets}
\end{abstract}

        